# Baseline: Sber Annual Report 2022 (2026-02-09)

- Dataset: `eval/questions.jsonl`
- Questions: `24`
- Model: `GigaChat-2-Max`
- Run type: current implementation baseline

## Aggregate

- **weighted_score: 0.6540384615384615**

## Command

```bash
GIGACHAT_API_KEY=*** ALLOW_DANGEROUS_FAISS_DESERIALIZATION=1 PYTHONPATH=. \
python eval/run_eval.py \
  --pdf eval/data/source.pdf \
  --questions eval/questions.jsonl \
  --out eval/runs/baseline.json
```

## Lowest-scoring questions (for first improvement iteration)

- q002 — score 0.300 (include 0/1)
- q003 — score 0.300 (include 0/1)
- q004 — score 0.300 (include 0/2)
- q005 — score 0.300 (include 0/1)
- q006 — score 0.300 (include 0/2)

> Full raw run is stored locally at `eval/runs/baseline.json` (ignored by git).
